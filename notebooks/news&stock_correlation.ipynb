{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "import yfinance as yf\n",
    "import numpy as np\n",
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load news headlines data\n",
    "news_data = pd.read_csv('../data/raw_analyst_ratings.csv')\n",
    "stock_data= pd.read_csv('../data/all_stock_data2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Unnamed: 0                                           headline  \\\n",
      "0                 0            Stocks That Hit 52-Week Highs On Friday   \n",
      "1                 1         Stocks That Hit 52-Week Highs On Wednesday   \n",
      "2                 2                      71 Biggest Movers From Friday   \n",
      "3                 3       46 Stocks Moving In Friday's Mid-Day Session   \n",
      "4                 4  B of A Securities Maintains Neutral on Agilent...   \n",
      "...             ...                                                ...   \n",
      "1407323     1413844             Top Narrow Based Indexes For August 29   \n",
      "1407324     1413845  Recap: Wednesday's Top Percentage Gainers and ...   \n",
      "1407325     1413846  UPDATE: Oppenheimer Color on China Zenix Auto ...   \n",
      "1407326     1413847  Oppenheimer Initiates China Zenix At Outperfor...   \n",
      "1407327     1413848  China Zenix Auto International Opens For Tradi...   \n",
      "\n",
      "                                                       url          publisher  \\\n",
      "0        https://www.benzinga.com/news/20/06/16190091/s...  Benzinga Insights   \n",
      "1        https://www.benzinga.com/news/20/06/16170189/s...  Benzinga Insights   \n",
      "2        https://www.benzinga.com/news/20/05/16103463/7...         Lisa Levin   \n",
      "3        https://www.benzinga.com/news/20/05/16095921/4...         Lisa Levin   \n",
      "4        https://www.benzinga.com/news/20/05/16095304/b...         Vick Meyer   \n",
      "...                                                    ...                ...   \n",
      "1407323  https://www.benzinga.com/news/11/08/1888782/to...      Monica Gerson   \n",
      "1407324  https://www.benzinga.com/news/earnings/11/06/1...       Benjamin Lee   \n",
      "1407325  https://www.benzinga.com/analyst-ratings/analy...     BenzingaStaffL   \n",
      "1407326  https://www.benzinga.com/analyst-ratings/price...          Joe Young   \n",
      "1407327  https://www.benzinga.com/news/ipos/11/05/10789...      Allie Wickman   \n",
      "\n",
      "                              date stock  \n",
      "0        2020-06-05 10:30:54-04:00     A  \n",
      "1        2020-06-03 10:45:20-04:00     A  \n",
      "2        2020-05-26 04:30:07-04:00     A  \n",
      "3        2020-05-22 12:45:06-04:00     A  \n",
      "4        2020-05-22 11:38:59-04:00     A  \n",
      "...                            ...   ...  \n",
      "1407323        2011-08-29 00:00:00    ZX  \n",
      "1407324        2011-06-22 00:00:00    ZX  \n",
      "1407325        2011-06-21 00:00:00    ZX  \n",
      "1407326        2011-06-21 00:00:00    ZX  \n",
      "1407327        2011-05-12 00:00:00    ZX  \n",
      "\n",
      "[1407328 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "print(news_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Date       Open       High        Low      Close  Adj Close  \\\n",
      "0        2013-03-05  33.310001  33.310001  33.310001  33.310001  30.201914   \n",
      "1        2013-03-06  33.290001  33.290001  33.220001  33.220001  30.120306   \n",
      "2        2013-03-07  33.410000  33.410000  32.970001  33.130001  30.038700   \n",
      "3        2013-03-08  33.009998  33.250000  33.009998  33.250000  30.147512   \n",
      "4        2013-03-11  33.330002  33.360001  32.959999  33.060001  29.975235   \n",
      "...             ...        ...        ...        ...        ...        ...   \n",
      "7454194  2020-05-29  24.350000  24.740000  23.809999  24.370001  24.370001   \n",
      "7454195  2020-06-01  24.389999  25.270000  23.719999  24.690001  24.690001   \n",
      "7454196  2020-06-02  25.100000  26.520000  24.660000  26.250000  26.250000   \n",
      "7454197  2020-06-03  26.760000  27.809999  26.049999  27.690001  27.690001   \n",
      "7454198  2020-06-04  27.530001  29.780001  27.530001  29.200001  29.200001   \n",
      "\n",
      "           Volume Symbol  \n",
      "0           300.0   AADR  \n",
      "1           300.0   AADR  \n",
      "2          1500.0   AADR  \n",
      "3          1300.0   AADR  \n",
      "4          1800.0   AADR  \n",
      "...           ...    ...  \n",
      "7454194  591600.0   ZUMZ  \n",
      "7454195  386500.0   ZUMZ  \n",
      "7454196  366100.0   ZUMZ  \n",
      "7454197  363400.0   ZUMZ  \n",
      "7454198  692500.0   ZUMZ  \n",
      "\n",
      "[7454199 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "print(stock_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'news_data' is your DataFrame containing the 'date' column\n",
    "news_data['date'] = pd.to_datetime(news_data['date'])  # Convert to datetime object\n",
    "news_data['date'] = news_data['date'].dt.strftime('%Y-%m-%d')  # Format date as '%Y-%m-%d'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0          2020-06-05\n",
      "1          2020-06-03\n",
      "2          2020-05-26\n",
      "3          2020-05-22\n",
      "4          2020-05-22\n",
      "              ...    \n",
      "1407323    2011-08-29\n",
      "1407324    2011-06-22\n",
      "1407325    2011-06-21\n",
      "1407326    2011-06-21\n",
      "1407327    2011-05-12\n",
      "Name: date, Length: 1407328, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(news_data['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_data['Date'] = pd.to_datetime(stock_data['Date'], format='ISO8601')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         2013-03-05\n",
      "1         2013-03-06\n",
      "2         2013-03-07\n",
      "3         2013-03-08\n",
      "4         2013-03-11\n",
      "             ...    \n",
      "7454194   2020-05-29\n",
      "7454195   2020-06-01\n",
      "7454196   2020-06-02\n",
      "7454197   2020-06-03\n",
      "7454198   2020-06-04\n",
      "Name: Date, Length: 7454199, dtype: datetime64[ns]\n"
     ]
    }
   ],
   "source": [
    "print(stock_data['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply sentiment analysis to news headlines\n",
    "news_data['sentiment'] = news_data['headline'].apply(lambda x: TextBlob(x).sentiment.polarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0          0.00\n",
      "1          0.00\n",
      "2          0.00\n",
      "3          0.00\n",
      "4          0.00\n",
      "           ... \n",
      "1407323    0.15\n",
      "1407324    0.15\n",
      "1407325    0.00\n",
      "1407326    0.00\n",
      "1407327    0.00\n",
      "Name: sentiment, Length: 1407328, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(news_data['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate Stock Movements\n",
    "# Compute daily percentage change in closing prices to represent stock movements\n",
    "stock_data['Daily_Returns'] = stock_data['Close'].pct_change() * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation Analysis\n",
    "# Aggregate sentiment scores if multiple articles appear on the same day\n",
    "daily_sentiment = news_data.groupby('date')['sentiment'].mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure both datasets have the same dates\n",
    "merged_data = pd.concat([daily_sentiment, stock_data], axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged dataset:\n",
      "               date  sentiment       Date       Open       High        Low  \\\n",
      "0        2009-02-14   0.000000 2013-03-05  33.310001  33.310001  33.310001   \n",
      "1        2009-04-27   0.000000 2013-03-06  33.290001  33.290001  33.220001   \n",
      "2        2009-04-29   0.000000 2013-03-07  33.410000  33.410000  32.970001   \n",
      "3        2009-05-22   0.000000 2013-03-08  33.009998  33.250000  33.009998   \n",
      "4        2009-05-27   0.234091 2013-03-11  33.330002  33.360001  32.959999   \n",
      "...             ...        ...        ...        ...        ...        ...   \n",
      "7454194         NaN        NaN 2020-05-29  24.350000  24.740000  23.809999   \n",
      "7454195         NaN        NaN 2020-06-01  24.389999  25.270000  23.719999   \n",
      "7454196         NaN        NaN 2020-06-02  25.100000  26.520000  24.660000   \n",
      "7454197         NaN        NaN 2020-06-03  26.760000  27.809999  26.049999   \n",
      "7454198         NaN        NaN 2020-06-04  27.530001  29.780001  27.530001   \n",
      "\n",
      "             Close  Adj Close    Volume Symbol  Daily_Returns  \n",
      "0        33.310001  30.201914     300.0   AADR            NaN  \n",
      "1        33.220001  30.120306     300.0   AADR      -0.270190  \n",
      "2        33.130001  30.038700    1500.0   AADR      -0.270922  \n",
      "3        33.250000  30.147512    1300.0   AADR       0.362206  \n",
      "4        33.060001  29.975235    1800.0   AADR      -0.571424  \n",
      "...            ...        ...       ...    ...            ...  \n",
      "7454194  24.370001  24.370001  591600.0   ZUMZ      -1.375954  \n",
      "7454195  24.690001  24.690001  386500.0   ZUMZ       1.313089  \n",
      "7454196  26.250000  26.250000  366100.0   ZUMZ       6.318345  \n",
      "7454197  27.690001  27.690001  363400.0   ZUMZ       5.485716  \n",
      "7454198  29.200001  29.200001  692500.0   ZUMZ       5.453233  \n",
      "\n",
      "[7454199 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "print(\"Merged dataset:\")\n",
    "print(merged_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in sentiment: 7450244\n",
      "Missing values in Daily_Returns: 1\n",
      "Infinite values in sentiment: 0\n",
      "Infinite values in Daily_Returns: 0\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "missing_sentiment = merged_data['sentiment'].isnull().sum()\n",
    "missing_returns = merged_data['Daily_Returns'].isnull().sum()\n",
    "print(\"Missing values in sentiment:\", missing_sentiment)\n",
    "print(\"Missing values in Daily_Returns:\", missing_returns)\n",
    "\n",
    "# Check for infinite values\n",
    "infinite_sentiment = np.isinf(merged_data['sentiment']).sum()\n",
    "infinite_returns = np.isinf(merged_data['Daily_Returns']).sum()\n",
    "print(\"Infinite values in sentiment:\", infinite_sentiment)\n",
    "print(\"Infinite values in Daily_Returns:\", infinite_returns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged dataset:\n",
      "               date  sentiment       Date       Open       High        Low  \\\n",
      "0        2009-02-14   0.000000 2013-03-05  33.310001  33.310001  33.310001   \n",
      "1        2009-04-27   0.000000 2013-03-06  33.290001  33.290001  33.220001   \n",
      "2        2009-04-29   0.000000 2013-03-07  33.410000  33.410000  32.970001   \n",
      "3        2009-05-22   0.000000 2013-03-08  33.009998  33.250000  33.009998   \n",
      "4        2009-05-27   0.234091 2013-03-11  33.330002  33.360001  32.959999   \n",
      "...             ...        ...        ...        ...        ...        ...   \n",
      "7454194         NaN        NaN 2020-05-29  24.350000  24.740000  23.809999   \n",
      "7454195         NaN        NaN 2020-06-01  24.389999  25.270000  23.719999   \n",
      "7454196         NaN        NaN 2020-06-02  25.100000  26.520000  24.660000   \n",
      "7454197         NaN        NaN 2020-06-03  26.760000  27.809999  26.049999   \n",
      "7454198         NaN        NaN 2020-06-04  27.530001  29.780001  27.530001   \n",
      "\n",
      "             Close  Adj Close    Volume Symbol  Daily_Returns  \n",
      "0        33.310001  30.201914     300.0   AADR            NaN  \n",
      "1        33.220001  30.120306     300.0   AADR      -0.270190  \n",
      "2        33.130001  30.038700    1500.0   AADR      -0.270922  \n",
      "3        33.250000  30.147512    1300.0   AADR       0.362206  \n",
      "4        33.060001  29.975235    1800.0   AADR      -0.571424  \n",
      "...            ...        ...       ...    ...            ...  \n",
      "7454194  24.370001  24.370001  591600.0   ZUMZ      -1.375954  \n",
      "7454195  24.690001  24.690001  386500.0   ZUMZ       1.313089  \n",
      "7454196  26.250000  26.250000  366100.0   ZUMZ       6.318345  \n",
      "7454197  27.690001  27.690001  363400.0   ZUMZ       5.485716  \n",
      "7454198  29.200001  29.200001  692500.0   ZUMZ       5.453233  \n",
      "\n",
      "[7454199 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "print(\"Merged dataset:\")\n",
    "print(merged_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7454199\n",
      "7454199\n"
     ]
    }
   ],
   "source": [
    "print(len(merged_data['sentiment']))\n",
    "print(len(merged_data['Daily_Returns']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson correlation coefficient: 0.015239236844272882\n",
      "p-value: 0.33805839591930076\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "# Check for NaN or infinite values in the arrays\n",
    "nan_mask = np.isnan(merged_data['sentiment']) | np.isnan(merged_data['Daily_Returns'])\n",
    "inf_mask = np.isinf(merged_data['sentiment']) | np.isinf(merged_data['Daily_Returns'])\n",
    "\n",
    "# Combine NaN and infinite masks\n",
    "invalid_mask = nan_mask | inf_mask\n",
    "\n",
    "# Remove invalid values from both arrays\n",
    "clean_sentiment = merged_data['sentiment'][~invalid_mask]\n",
    "clean_returns = merged_data['Daily_Returns'][~invalid_mask]\n",
    "\n",
    "# Calculate Pearson correlation coefficient between clean sentiment scores and stock returns\n",
    "correlation_coefficient, p_value = pearsonr(clean_sentiment, clean_returns)\n",
    "print(\"Pearson correlation coefficient:\", correlation_coefficient)\n",
    "print(\"p-value:\", p_value)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
