{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import yfinance as yf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "stock_data= pd.read_csv('../data/raw_analyst_ratings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of          Unnamed: 0                                           headline  \\\n",
      "0                 0            Stocks That Hit 52-Week Highs On Friday   \n",
      "1                 1         Stocks That Hit 52-Week Highs On Wednesday   \n",
      "2                 2                      71 Biggest Movers From Friday   \n",
      "3                 3       46 Stocks Moving In Friday's Mid-Day Session   \n",
      "4                 4  B of A Securities Maintains Neutral on Agilent...   \n",
      "...             ...                                                ...   \n",
      "1407323     1413844             Top Narrow Based Indexes For August 29   \n",
      "1407324     1413845  Recap: Wednesday's Top Percentage Gainers and ...   \n",
      "1407325     1413846  UPDATE: Oppenheimer Color on China Zenix Auto ...   \n",
      "1407326     1413847  Oppenheimer Initiates China Zenix At Outperfor...   \n",
      "1407327     1413848  China Zenix Auto International Opens For Tradi...   \n",
      "\n",
      "                                                       url          publisher  \\\n",
      "0        https://www.benzinga.com/news/20/06/16190091/s...  Benzinga Insights   \n",
      "1        https://www.benzinga.com/news/20/06/16170189/s...  Benzinga Insights   \n",
      "2        https://www.benzinga.com/news/20/05/16103463/7...         Lisa Levin   \n",
      "3        https://www.benzinga.com/news/20/05/16095921/4...         Lisa Levin   \n",
      "4        https://www.benzinga.com/news/20/05/16095304/b...         Vick Meyer   \n",
      "...                                                    ...                ...   \n",
      "1407323  https://www.benzinga.com/news/11/08/1888782/to...      Monica Gerson   \n",
      "1407324  https://www.benzinga.com/news/earnings/11/06/1...       Benjamin Lee   \n",
      "1407325  https://www.benzinga.com/analyst-ratings/analy...     BenzingaStaffL   \n",
      "1407326  https://www.benzinga.com/analyst-ratings/price...          Joe Young   \n",
      "1407327  https://www.benzinga.com/news/ipos/11/05/10789...      Allie Wickman   \n",
      "\n",
      "                              date stock  \n",
      "0        2020-06-05 10:30:54-04:00     A  \n",
      "1        2020-06-03 10:45:20-04:00     A  \n",
      "2        2020-05-26 04:30:07-04:00     A  \n",
      "3        2020-05-22 12:45:06-04:00     A  \n",
      "4        2020-05-22 11:38:59-04:00     A  \n",
      "...                            ...   ...  \n",
      "1407323        2011-08-29 00:00:00    ZX  \n",
      "1407324        2011-06-22 00:00:00    ZX  \n",
      "1407325        2011-06-21 00:00:00    ZX  \n",
      "1407326        2011-06-21 00:00:00    ZX  \n",
      "1407327        2011-05-12 00:00:00    ZX  \n",
      "\n",
      "[1407328 rows x 6 columns]>\n"
     ]
    }
   ],
   "source": [
    "print(stock_data.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the Data\n",
    "stock_data['date'] = pd.to_datetime(stock_data['date'], format='ISO8601')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Unnamed: 0                                           headline  \\\n",
      "0                 0            Stocks That Hit 52-Week Highs On Friday   \n",
      "1                 1         Stocks That Hit 52-Week Highs On Wednesday   \n",
      "2                 2                      71 Biggest Movers From Friday   \n",
      "3                 3       46 Stocks Moving In Friday's Mid-Day Session   \n",
      "4                 4  B of A Securities Maintains Neutral on Agilent...   \n",
      "...             ...                                                ...   \n",
      "1407323     1413844             Top Narrow Based Indexes For August 29   \n",
      "1407324     1413845  Recap: Wednesday's Top Percentage Gainers and ...   \n",
      "1407325     1413846  UPDATE: Oppenheimer Color on China Zenix Auto ...   \n",
      "1407326     1413847  Oppenheimer Initiates China Zenix At Outperfor...   \n",
      "1407327     1413848  China Zenix Auto International Opens For Tradi...   \n",
      "\n",
      "                                                       url          publisher  \\\n",
      "0        https://www.benzinga.com/news/20/06/16190091/s...  Benzinga Insights   \n",
      "1        https://www.benzinga.com/news/20/06/16170189/s...  Benzinga Insights   \n",
      "2        https://www.benzinga.com/news/20/05/16103463/7...         Lisa Levin   \n",
      "3        https://www.benzinga.com/news/20/05/16095921/4...         Lisa Levin   \n",
      "4        https://www.benzinga.com/news/20/05/16095304/b...         Vick Meyer   \n",
      "...                                                    ...                ...   \n",
      "1407323  https://www.benzinga.com/news/11/08/1888782/to...      Monica Gerson   \n",
      "1407324  https://www.benzinga.com/news/earnings/11/06/1...       Benjamin Lee   \n",
      "1407325  https://www.benzinga.com/analyst-ratings/analy...     BenzingaStaffL   \n",
      "1407326  https://www.benzinga.com/analyst-ratings/price...          Joe Young   \n",
      "1407327  https://www.benzinga.com/news/ipos/11/05/10789...      Allie Wickman   \n",
      "\n",
      "                             date stock  \n",
      "0       2020-06-05 10:30:54-04:00     A  \n",
      "1       2020-06-03 10:45:20-04:00     A  \n",
      "2       2020-05-26 04:30:07-04:00     A  \n",
      "3       2020-05-22 12:45:06-04:00     A  \n",
      "4       2020-05-22 11:38:59-04:00     A  \n",
      "...                           ...   ...  \n",
      "1407323 2011-08-29 00:00:00-04:00    ZX  \n",
      "1407324 2011-06-22 00:00:00-04:00    ZX  \n",
      "1407325 2011-06-21 00:00:00-04:00    ZX  \n",
      "1407326 2011-06-21 00:00:00-04:00    ZX  \n",
      "1407327 2011-05-12 00:00:00-04:00    ZX  \n",
      "\n",
      "[1407328 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "print(stock_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify Stock Symbols and Date Ranges\n",
    "date_ranges = stock_data.groupby('stock')['date'].agg(start_date='min', end_date='max')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     start_date                  end_date\n",
      "stock                                                    \n",
      "A     2009-04-29 00:00:00-04:00 2020-06-05 10:30:54-04:00\n",
      "AA    2009-08-10 00:00:00-04:00 2020-06-09 10:52:15-04:00\n",
      "AAC   2010-03-25 00:00:00-04:00 2019-10-25 16:09:59-04:00\n",
      "AADR  2013-03-05 15:42:46-04:00 2013-09-06 15:06:35-04:00\n",
      "AAL   2011-05-16 00:00:00-04:00 2020-06-10 11:21:01-04:00\n",
      "...                         ...                       ...\n",
      "ZTR   2009-08-10 00:00:00-04:00 2020-03-19 10:49:42-04:00\n",
      "ZTS   2013-01-17 00:00:00-04:00 2020-06-11 10:22:31-04:00\n",
      "ZU    2013-11-14 00:00:00-04:00 2020-01-09 14:34:23-04:00\n",
      "ZUMZ  2009-11-16 00:00:00-04:00 2020-06-05 07:24:15-04:00\n",
      "ZX    2011-05-12 00:00:00-04:00 2018-06-15 09:01:12-04:00\n",
      "\n",
      "[6204 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(date_ranges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine date ranges and fetch stock data\n",
    "# Calculate the earliest and latest date for each stock to define the period for which to fetch stock prices\n",
    "stock_date_ranges = stock_data.groupby('stock').agg({'date': ['min', 'max']})\n",
    "stock_date_ranges.columns = ['earliest_date', 'latest_date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  earliest_date               latest_date\n",
      "stock                                                    \n",
      "A     2009-04-29 00:00:00-04:00 2020-06-05 10:30:54-04:00\n",
      "AA    2009-08-10 00:00:00-04:00 2020-06-09 10:52:15-04:00\n",
      "AAC   2010-03-25 00:00:00-04:00 2019-10-25 16:09:59-04:00\n",
      "AADR  2013-03-05 15:42:46-04:00 2013-09-06 15:06:35-04:00\n",
      "AAL   2011-05-16 00:00:00-04:00 2020-06-10 11:21:01-04:00\n",
      "...                         ...                       ...\n",
      "ZTR   2009-08-10 00:00:00-04:00 2020-03-19 10:49:42-04:00\n",
      "ZTS   2013-01-17 00:00:00-04:00 2020-06-11 10:22:31-04:00\n",
      "ZU    2013-11-14 00:00:00-04:00 2020-01-09 14:34:23-04:00\n",
      "ZUMZ  2009-11-16 00:00:00-04:00 2020-06-05 07:24:15-04:00\n",
      "ZX    2011-05-12 00:00:00-04:00 2018-06-15 09:01:12-04:00\n",
      "\n",
      "[6204 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(stock_date_ranges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock data for A downloaded successfully.\n",
      "Stock data downloaded:                  Open       High        Low      Close  Adj Close   Volume  \\\n",
      "Date                                                                         \n",
      "2009-04-29  12.310443  13.011445  12.238913  12.896996  11.591171  5516508   \n",
      "2009-04-30  12.947067  13.547926  12.947067  13.061516  11.739037  4977998   \n",
      "2009-05-01  13.025751  13.590844  13.004292  13.454936  12.092619  4039241   \n",
      "2009-05-04  13.454936  13.891273  13.412017  13.891273  12.484780  3885042   \n",
      "2009-05-05  13.848355  13.876967  13.283262  13.397711  12.041190  4895656   \n",
      "\n",
      "           Symbol  \n",
      "Date               \n",
      "2009-04-29      A  \n",
      "2009-04-30      A  \n",
      "2009-05-01      A  \n",
      "2009-05-04      A  \n",
      "2009-05-05      A  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for stock_symbol in stock_date_ranges.index.unique():\n",
    "    # Get the date range for the current symbol\n",
    "    date_range = stock_date_ranges.loc[stock_symbol]\n",
    "    start_date = date_range['earliest_date']\n",
    "    end_date = date_range['latest_date']\n",
    "    \n",
    "    try:\n",
    "        # Download stock data\n",
    "        stock_data = yf.download(stock_symbol, start=start_date, end=end_date)\n",
    "        \n",
    "        # Add stock symbol as a column in the DataFrame\n",
    "        stock_data['Symbol'] = stock_symbol\n",
    "        \n",
    "        # Append stock data to the DataFrame containing all stock data\n",
    "        all_stock_data = pd.concat([all_stock_data, stock_data])\n",
    "        \n",
    "        print(\"Stock data for\", stock_symbol, \"downloaded successfully.\")\n",
    "        \n",
    "        # Display the result after downloading for one symbol\n",
    "        print(\"Stock data downloaded:\", all_stock_data.head())\n",
    "        \n",
    "        # Break out of the loop\n",
    "        break\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(\"Failed to download stock data for\", stock_symbol, \":\", str(e))\n",
    "\n",
    "# Save all stock data to a single CSV file\n",
    "all_stock_data.to_csv('all_stock_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use yfinance to download stock data for each stock based on the calculated date ranges\n",
    "# Initialize an empty DataFrame to store all stock data\n",
    "\n",
    "# Loop through date ranges and download stock data for each symbol\n",
    "for index, row in stock_date_ranges.iterrows():\n",
    "    stock_symbol = index\n",
    "    start_date = row['earliest_date']\n",
    "    end_date = row['latest_date']\n",
    "    \n",
    "    try:\n",
    "        # Download stock data\n",
    "        stock_data = yf.download(stock_symbol, start=start_date, end=end_date)\n",
    "        \n",
    "        # Add stock symbol as a column in the DataFrame\n",
    "        stock_data['Symbol'] = stock_symbol\n",
    "        \n",
    "        # Append stock data to the DataFrame containing all stock data\n",
    "        all_stock_data = pd.concat([all_stock_data, stock_data])\n",
    "        \n",
    "        \n",
    "        print(\"Stock data for\", stock_symbol, \"downloaded successfully.\")\n",
    "    except Exception as e:\n",
    "        print(\"Failed to download stock data for\", stock_symbol, \":\", str(e))\n",
    "\n",
    "# Save all stock data to a single CSV file\n",
    "all_stock_data.to_csv('all_stock_data.csv')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
